# KCP ML Shop demo

This is a demo of a simple machine-learning service, hosted on KCP.
It shows how to use the [KCP](https://kcp.io) as a platform to deploy a 
machine-learning model and expose it as a REST API.
Use global shards to run models close to data (geo placement).

Demo recording: https://youtu.be/7op_r9R0fCo?si=8KxUnEgSASBRJCFG&t=1515 

## Pre-requisites

- KCP running with shards - shards `root` and `beta` are required. 
  - See [KCP sharded helm example](https://github.com/kcp-dev/helm-charts/tree/main/examples/sharded)
- Kubectl installed
- Kubectl-workspace plugin installed

## Demo scenario

### Platform operator persona 

The platform operator is responsible for setting up the platform and enabling 3rd party.
This is done by creating APIExports and APIBindings in dedicated workspace.
Workspace management is done via `kubectl-workspace` plugin.

```bash
export KUBECONFIG=kcp.kubeconfig
```

1. Show current "platform backend" view:

```bash
k ws tree
```

2. Bootstrap the assets. This shows the platforms provider enabling 3rd party to handle
the management of certain resources via APIBindings:

```bash
go run ./cmd/controller/ init --kubeconfig=kcp.kubeconfig
k ws tree
```

3. Show what server side looks like:

```bash
k ws use root:ml:training
k get apiexports
k get apiexport -o yaml
```

Now that a platform owner has pre-created assets, and 3rd party can use them to deploy models,
let us move to service provider persona. 

Important: In the demo we used the same `kcp.kubeconfig` for both platform operator and service provider.
In real-world scenario, those would be different kubeconfigs, preferably generated by the platform operator
and certificate-based. 

### Service provider persona

1. The service provider has a controller to run pointing to this APIExport:

```bash
export KUBECONFIG=idp.kubeconfig
```

Important: Mount code is not yet open-sourced and it's a work in progress.
The cluster running the controller has to have access to both APIExport exported URLs,
showed in the previous step. In a real-world scenario, this would be done via VPN or other secure means,
where shards can be accessed.

1. Deploy the controller:

```bash
k apply -f ../kcp-ml-shop/demo/deploy/namespace.yaml
k create secret generic kubeconfig --from-file=kcp.kubeconfig -n ml
k apply -f ../kcp-ml-shop/demo/deploy/deploy.yaml
```


### User persona

1. User has a model to deploy - Create an ML-enabled workspace (in 2 locations):

```bash
k ws create ml-europe --location-selector=name=root --type ml-training
k ws create ml-us --location-selector=name=beta --type ml-training
```

5. Deploy the model

```bash
cat demo/model.yaml
k ws use ml-europe
k create -f demo/model.yaml
# get to US:
k ws use ..
k ws use ml-us
k create -f demo/model.yaml
```
